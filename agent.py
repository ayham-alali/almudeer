"""
Al-Mudeer - LangGraph InboxCRM Agent
Implements: Ingest -> Classify -> Extract -> Draft pipeline
Optimized for low bandwidth with text-only responses
"""

import json
import re
from typing import TypedDict, Literal, Optional, Dict, Any
from dataclasses import dataclass
import httpx
import os

# LangGraph imports
from langgraph.graph import StateGraph, END

# Configuration
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4.1-mini")
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")

# Base system prompt for Arabic business context
BASE_SYSTEM_PROMPT = """ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ŸÖŸÉÿ™ÿ®Ÿä ÿ∞ŸÉŸä ŸÑŸÑÿ¥ÿ±ŸÉÿßÿ™ ŸÅŸä ÿßŸÑÿπÿßŸÑŸÖ ÿßŸÑÿπÿ±ÿ®Ÿä. ÿ™ÿ™ÿ≠ÿØÿ´ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑŸÅÿµÿ≠Ÿâ ÿ®ÿ£ÿ≥ŸÑŸàÿ® ŸÖŸáŸÜŸä ŸàŸÖŸáÿ∞ÿ®.
ÿ™ŸÅŸáŸÖ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ŸÑŸä ÿ¨ŸäÿØÿßŸã (ÿßŸÑÿπŸÖŸÑÿ©ÿå ÿßŸÑÿπÿßÿØÿßÿ™ÿå ÿ£ÿ≥ŸÑŸàÿ® ÿßŸÑÿ™ÿÆÿßÿ∑ÿ®).
ŸÖŸáŸÖÿ™ŸÉ ŸáŸä ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ±ÿ≥ÿßÿ¶ŸÑ ÿßŸÑŸàÿßÿ±ÿØÿ© Ÿàÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿßŸÑŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ© ŸàÿµŸäÿßÿ∫ÿ© ÿ±ÿØŸàÿØ ŸÖŸÜÿßÿ≥ÿ®ÿ©.
ŸÉŸÜ ŸÖŸàÿ¨ÿ≤ÿßŸã ŸàŸÖÿ®ÿßÿ¥ÿ±ÿßŸã ŸÅŸä ÿ±ÿØŸàÿØŸÉ ŸÑÿ™ŸàŸÅŸäÿ± ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™."""


def build_system_prompt(preferences: Optional[Dict[str, Any]] = None) -> str:
    """
    Build a system prompt customized by workspace preferences.

    preferences comes from user_preferences table and may include:
    - tone: formal | friendly | custom
    - custom_tone_guidelines
    - business_name, industry, products_services
    - preferred_languages, reply_length, formality_level
    """
    if not preferences:
        return BASE_SYSTEM_PROMPT

    tone = (preferences.get("tone") or "formal").lower()
    custom_guidelines = (preferences.get("custom_tone_guidelines") or "").strip()

    # Tone description
    if tone == "friendly":
        tone_desc = "ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÜÿ®ÿ±ÿ© ŸàÿØŸäÿ© ŸàŸÇÿ±Ÿäÿ®ÿ© ŸÑŸÉŸÜ ŸÖÿπ ÿßÿ≠ÿ™ÿ±ÿßŸÖ ŸÖŸáŸÜŸäÿå Ÿàÿ™ÿ¨ŸÜŸëÿ® ÿßŸÑÿπÿßŸÖŸäÿ© ÿßŸÑÿ´ŸÇŸäŸÑÿ©."
    elif tone == "custom" and custom_guidelines:
        tone_desc = custom_guidelines
    else:
        # formal or unknown
        tone_desc = "ÿßÿ≥ÿ™ÿÆÿØŸÖ ŸÜÿ®ÿ±ÿ© ÿ±ÿ≥ŸÖŸäÿ© ÿ®ÿ≥Ÿäÿ∑ÿ© ŸàŸàÿßÿ∂ÿ≠ÿ© ÿ®ÿØŸàŸÜ ŸÖÿ®ÿßŸÑÿ∫ÿ© ŸÅŸä ÿßŸÑŸÖÿ¨ÿßŸÖŸÑÿßÿ™."

    business_name = preferences.get("business_name") or "ÿßŸÑÿ¥ÿ±ŸÉÿ©"
    industry = preferences.get("industry") or ""
    products = preferences.get("products_services") or ""

    business_context_parts = [f"ÿ™ÿ™ÿ≠ÿØÿ´ ÿ®ÿßÿ≥ŸÖ {business_name}."]
    if industry:
        business_context_parts.append(f"ÿßŸÑŸÜÿ¥ÿßÿ∑ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä: {industry}.")
    if products:
        business_context_parts.append(f"ÿßŸÑÿÆÿØŸÖÿßÿ™ / ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©: {products}.")

    reply_length = (preferences.get("reply_length") or "").lower()
    if reply_length == "short":
        length_hint = "ÿßÿ≠ÿ±ÿµ ÿ£ŸÜ ŸäŸÉŸàŸÜ ÿßŸÑÿ±ÿØ ŸÇÿµŸäÿ±ÿßŸã ŸÇÿØÿ± ÿßŸÑÿ•ŸÖŸÉÿßŸÜ (ŸÖŸÜ 2 ÿ•ŸÑŸâ 3 ÿ£ÿ≥ÿ∑ÿ± ÿ™ŸÇÿ±Ÿäÿ®ÿßŸã)."
    elif reply_length == "long":
        length_hint = "ŸäŸÖŸÉŸÜ ÿ£ŸÜ ŸäŸÉŸàŸÜ ÿßŸÑÿ±ÿØ ŸÖŸÅÿµŸÑÿßŸã ÿ£ŸÉÿ´ÿ± ÿπŸÜÿØ ÿßŸÑÿ≠ÿßÿ¨ÿ©ÿå ŸÖÿπ ÿßŸÑŸÖÿ≠ÿßŸÅÿ∏ÿ© ÿπŸÑŸâ ÿßŸÑŸàÿ∂Ÿàÿ≠."
    else:
        length_hint = "ÿ≠ÿßŸÅÿ∏ ÿπŸÑŸâ ÿ∑ŸàŸÑ ÿ±ÿØ ŸÖÿ™Ÿàÿ≥ÿ∑ ŸàŸàÿßÿ∂ÿ≠ (ÿ≠ŸàÿßŸÑŸä 3 ÿ•ŸÑŸâ 6 ÿ£ÿ≥ÿ∑ÿ±)."

    return (
        BASE_SYSTEM_PROMPT
        + "\n\n"
        + "ÿ≥ŸäÿßŸÇ ÿßŸÑÿπŸÖŸÑ:\n"
        + " ".join(business_context_parts)
        + "\n\nÿ£ÿ≥ŸÑŸàÿ® ÿßŸÑŸÉÿ™ÿßÿ®ÿ© ÿßŸÑŸÖÿ∑ŸÑŸàÿ®:\n"
        + tone_desc
        + "\n"
        + length_hint
    )


class AgentState(TypedDict):
    """State for the InboxCRM agent"""
    # Input
    raw_message: str
    message_type: str  # email, whatsapp, general
    
    # Classification
    intent: str  # ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±, ÿ∑ŸÑÿ® ÿÆÿØŸÖÿ©, ÿ¥ŸÉŸàŸâ, ŸÖÿ™ÿßÿ®ÿπÿ©, ÿπÿ±ÿ∂, ÿ£ÿÆÿ±Ÿâ
    urgency: str  # ÿπÿßÿ¨ŸÑ, ÿπÿßÿØŸä, ŸÖŸÜÿÆŸÅÿ∂
    sentiment: str  # ÿ•Ÿäÿ¨ÿßÿ®Ÿä, ŸÖÿ≠ÿßŸäÿØ, ÿ≥ŸÑÿ®Ÿä
    language: Optional[str]
    dialect: Optional[str]
    
    # Extraction
    sender_name: Optional[str]
    sender_contact: Optional[str]
    key_points: list[str]
    action_items: list[str]
    extracted_entities: dict  # dates, amounts, product names, etc.
    
    # Output
    summary: str
    draft_response: str
    suggested_actions: list[str]
    
    # Metadata
    error: Optional[str]
    processing_step: str

    # Preferences / context
    preferences: Optional[Dict[str, Any]]
    # Recent conversation history (plain text)
    conversation_history: Optional[str]


async def call_llm(
    prompt: str,
    system: Optional[str] = None,
    json_mode: bool = False,
    max_tokens: int = 600,
) -> Optional[str]:
    """
    Call OpenAI Chat Completions API.

    - Uses Arabic business system prompt.
    - Supports JSON-mode responses for structured outputs.
    - Falls back to None if the call fails so that rule-based logic can run.
    - Retries on 429 (rate limit) errors with exponential backoff.
    """
    if not OPENAI_API_KEY:
        # No API key configured; caller should fall back to rule-based logic
        return None

    effective_system = system or BASE_SYSTEM_PROMPT
    
    # Retry configuration for rate limiting
    max_retries = 3
    base_delay = 1.0  # seconds
    
    import asyncio

    for attempt in range(max_retries):
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                body: dict = {
                    "model": OPENAI_MODEL,
                    "messages": [
                        {"role": "system", "content": effective_system},
                        {"role": "user", "content": prompt},
                    ],
                    "temperature": 0.3,
                    "max_tokens": max_tokens,
                }

                if json_mode:
                    # Ask OpenAI to produce valid JSON
                    body["response_format"] = {"type": "json_object"}

                response = await client.post(
                    f"{OPENAI_BASE_URL}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {OPENAI_API_KEY}",
                        "Content-Type": "application/json",
                    },
                    json=body,
                )

                # Handle rate limiting with retry
                if response.status_code == 429:
                    if attempt < max_retries - 1:
                        delay = base_delay * (2 ** attempt)  # Exponential backoff
                        print(f"Rate limited (429), retrying in {delay}s (attempt {attempt + 1}/{max_retries})")
                        await asyncio.sleep(delay)
                        continue
                    else:
                        print("Rate limit exceeded after max retries")
                        return None

                response.raise_for_status()
                data = response.json()
                content = (
                    data.get("choices", [{}])[0]
                    .get("message", {})
                    .get("content", "")
                )
                return content.strip() if content else None
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 429 and attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)
                print(f"Rate limited (429), retrying in {delay}s (attempt {attempt + 1}/{max_retries})")
                await asyncio.sleep(delay)
                continue
            print(f"LLM call failed: {e}")
            return None
        except Exception as e:
            print(f"LLM call failed: {e}")
            return None
    
    return None


def rule_based_classify(message: str) -> dict:
    """Rule-based classification fallback (works offline)"""
    message_lower = message.lower()
    
    # Intent detection
    intent = "ÿ£ÿÆÿ±Ÿâ"
    if any(word in message for word in ["ÿ≥ÿπÿ±", "ŸÉŸÖ", "ÿ™ŸÉŸÑŸÅÿ©", "ÿ£ÿ≥ÿπÿßÿ±"]):
        intent = "ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±"
    elif any(word in message for word in ["ÿ£ÿ±ŸäÿØ", "ÿ£ÿ±ÿ∫ÿ®", "ÿ∑ŸÑÿ®", "ÿßÿ≠ÿ™ÿßÿ¨", "ŸÜÿ±ŸäÿØ"]):
        intent = "ÿ∑ŸÑÿ® ÿÆÿØŸÖÿ©"
    elif any(word in message for word in ["ÿ¥ŸÉŸàŸâ", "ŸÖÿ¥ŸÉŸÑÿ©", "ŸÑŸÖ ŸäÿπŸÖŸÑ", "ÿ™ÿ£ÿÆÿ±", "ÿ≥Ÿäÿ°"]):
        intent = "ÿ¥ŸÉŸàŸâ"
    elif any(word in message for word in ["ŸÖÿ™ÿßÿ®ÿπÿ©", "ÿ®ÿÆÿµŸàÿµ", "ÿßÿ≥ÿ™ŸÉŸÖÿßŸÑ", "ÿ™ÿ∞ŸÉŸäÿ±"]):
        intent = "ŸÖÿ™ÿßÿ®ÿπÿ©"
    elif any(word in message for word in ["ÿπÿ±ÿ∂", "ÿÆÿµŸÖ", "ÿ™ÿÆŸÅŸäÿ∂", "ŸÅÿ±ÿµÿ©"]):
        intent = "ÿπÿ±ÿ∂"
    
    # Urgency detection
    urgency = "ÿπÿßÿØŸä"
    if any(word in message for word in ["ÿπÿßÿ¨ŸÑ", "ŸÅŸàÿ±Ÿä", "ÿßŸÑŸäŸàŸÖ", "ÿßŸÑÿ¢ŸÜ", "ÿ∂ÿ±Ÿàÿ±Ÿä"]):
        urgency = "ÿπÿßÿ¨ŸÑ"
    elif any(word in message for word in ["ŸÑÿßÿ≠ŸÇÿßŸã", "ÿπŸÜÿØŸÖÿß", "ŸÖÿ™Ÿâ ŸÖÿß"]):
        urgency = "ŸÖŸÜÿÆŸÅÿ∂"
    
    # Sentiment detection
    sentiment = "ŸÖÿ≠ÿßŸäÿØ"
    if any(word in message for word in ["ÿ¥ŸÉÿ±ÿßŸã", "ŸÖŸÖÿ™ÿßÿ≤", "ÿ±ÿßÿ¶ÿπ", "ÿ≥ÿπŸäÿØ", "ŸÖÿ≥ÿ±Ÿàÿ±"]):
        sentiment = "ÿ•Ÿäÿ¨ÿßÿ®Ÿä"
    elif any(word in message for word in ["ÿ∫ÿßÿ∂ÿ®", "ŸÖÿ≠ÿ®ÿ∑", "ÿ≥Ÿäÿ°", "ŸÖÿ≥ÿ™ÿßÿ°", "ŸÑŸÑÿ£ÿ≥ŸÅ"]):
        sentiment = "ÿ≥ŸÑÿ®Ÿä"
    
    return {"intent": intent, "urgency": urgency, "sentiment": sentiment}


def extract_entities(message: str) -> dict:
    """Extract entities using regex patterns"""
    entities = {}
    
    # Phone numbers (Syrian/Arabic format)
    phone_patterns = [
        r'(?:00963|\+963|0)?9\d{8}',  # Syrian mobile
        r'(?:00963|\+963|0)?11\d{7}',  # Damascus landline
        r'\d{3}[-.\s]?\d{3}[-.\s]?\d{4}',  # General format
    ]
    phones = []
    for pattern in phone_patterns:
        phones.extend(re.findall(pattern, message))
    if phones:
        entities["phones"] = list(set(phones))
    
    # Email
    emails = re.findall(r'[\w\.-]+@[\w\.-]+\.\w+', message)
    if emails:
        entities["emails"] = emails
    
    # Dates (Arabic format)
    dates = re.findall(r'\d{1,2}[/\-]\d{1,2}[/\-]\d{2,4}', message)
    if dates:
        entities["dates"] = dates
    
    # Money amounts
    amounts = re.findall(r'(\d+(?:,\d{3})*(?:\.\d+)?)\s*(?:ŸÑ\.ÿ≥|ŸÑŸäÿ±ÿ©|ÿØŸàŸÑÿßÿ±|\$|USD)', message)
    if amounts:
        entities["amounts"] = amounts
    
    # Extract possible name (after ÿßŸÑÿ≥ŸäÿØ/ÿßŸÑÿ≥ŸäÿØÿ©/ÿßŸÑÿ£ÿ≥ÿ™ÿßÿ∞)
    name_match = re.search(r'(?:ÿßŸÑÿ≥ŸäÿØ|ÿßŸÑÿ≥ŸäÿØÿ©|ÿßŸÑÿ£ÿ≥ÿ™ÿßÿ∞|ÿßŸÑÿ£ÿ≥ÿ™ÿßÿ∞ÿ©|ÿ£ÿÆŸä|ÿ£ÿÆÿ™Ÿä)\s+([\u0600-\u06FF\s]+)', message)
    if name_match:
        entities["mentioned_name"] = name_match.group(1).strip()
    
    return entities


def generate_rule_based_response(state: dict) -> str:
    """Generate a draft response based on intent"""
    intent = state.get("intent", "ÿ£ÿÆÿ±Ÿâ")
    sender = state.get("sender_name", "ÿßŸÑÿπŸÖŸäŸÑ ÿßŸÑŸÉÿ±ŸäŸÖ")
    
    templates = {
        "ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±": f"""ÿßŸÑÿ≥ŸäÿØ/ÿßŸÑÿ≥ŸäÿØÿ© {sender} ÿßŸÑŸÖÿ≠ÿ™ÿ±ŸÖ/ÿ©ÿå

ÿ¥ŸÉÿ±ÿßŸã ŸÑÿ™ŸàÿßÿµŸÑŸÉŸÖ ŸÖÿπŸÜÿß.

ÿ®ÿÆÿµŸàÿµ ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ŸÉŸÖÿå ŸÜŸàÿØ ÿ•ŸÅÿßÿØÿ™ŸÉŸÖ ÿ®ÿ£ŸÜ [ÿ£ÿ∂ŸÅ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ ŸáŸÜÿß].

ŸÜÿ±ÿ≠ÿ® ÿ®ÿ£Ÿä ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ÿßÿ™ ÿ•ÿ∂ÿßŸÅŸäÿ©.

ŸÖÿπ ÿ£ÿ∑Ÿäÿ® ÿßŸÑÿ™ÿ≠Ÿäÿßÿ™ÿå
ŸÅÿ±ŸäŸÇ ÿÆÿØŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ°""",
        
        "ÿ∑ŸÑÿ® ÿÆÿØŸÖÿ©": f"""ÿßŸÑÿ≥ŸäÿØ/ÿßŸÑÿ≥ŸäÿØÿ© {sender} ÿßŸÑŸÖÿ≠ÿ™ÿ±ŸÖ/ÿ©ÿå

ÿ¥ŸÉÿ±ÿßŸã ŸÑÿ´ŸÇÿ™ŸÉŸÖ ÿ®ÿÆÿØŸÖÿßÿ™ŸÜÿß.

ÿ™ŸÖ ÿßÿ≥ÿ™ŸÑÿßŸÖ ÿ∑ŸÑÿ®ŸÉŸÖ ÿ®ŸÜÿ¨ÿßÿ≠ Ÿàÿ≥Ÿäÿ™ŸÖ ÿßŸÑÿ™ŸàÿßÿµŸÑ ŸÖÿπŸÉŸÖ ŸÇÿ±Ÿäÿ®ÿßŸã ŸÑÿßÿ≥ÿ™ŸÉŸÖÿßŸÑ ÿßŸÑÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™.

ŸÑŸÑŸÖÿ™ÿßÿ®ÿπÿ© ÿ£Ÿà ÿßŸÑÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ÿå ŸÜÿ≠ŸÜ ÿ®ÿÆÿØŸÖÿ™ŸÉŸÖ.

ŸÖÿπ ÿ£ÿ∑Ÿäÿ® ÿßŸÑÿ™ÿ≠Ÿäÿßÿ™ÿå
ŸÅÿ±ŸäŸÇ ÿßŸÑŸÖÿ®Ÿäÿπÿßÿ™""",
        
        "ÿ¥ŸÉŸàŸâ": f"""ÿßŸÑÿ≥ŸäÿØ/ÿßŸÑÿ≥ŸäÿØÿ© {sender} ÿßŸÑŸÖÿ≠ÿ™ÿ±ŸÖ/ÿ©ÿå

ŸÜÿπÿ™ÿ∞ÿ± ÿπŸÜ ÿ£Ÿä ÿ•ÿ≤ÿπÿßÿ¨ ÿ≥ÿ®ÿ®ŸÜÿßŸá ŸÑŸÉŸÖ.

ÿ™ŸÖ ÿ™ÿ≥ÿ¨ŸäŸÑ ŸÖŸÑÿßÿ≠ÿ∏ÿßÿ™ŸÉŸÖ Ÿàÿ≥Ÿäÿ™ŸÖ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑŸÖŸàÿ∂Ÿàÿπ ÿ®ÿ£ŸÇÿµŸâ ÿ≥ÿ±ÿπÿ©.
ÿ≥ŸÜÿ™ŸàÿßÿµŸÑ ŸÖÿπŸÉŸÖ ÿÆŸÑÿßŸÑ [ÿ≠ÿØÿØ ÿßŸÑŸÖÿØÿ©] ŸÑÿ•ÿ∑ŸÑÿßÿπŸÉŸÖ ÿπŸÑŸâ ÿßŸÑŸÖÿ≥ÿ™ÿ¨ÿØÿßÿ™.

ŸÜŸÇÿØÿ± ÿµÿ®ÿ±ŸÉŸÖ Ÿàÿ™ŸÅŸáŸÖŸÉŸÖ.

ŸÖÿπ ÿ£ÿ∑Ÿäÿ® ÿßŸÑÿ™ÿ≠Ÿäÿßÿ™ÿå
ŸÅÿ±ŸäŸÇ ÿÆÿØŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ°""",
        
        "ŸÖÿ™ÿßÿ®ÿπÿ©": f"""ÿßŸÑÿ≥ŸäÿØ/ÿßŸÑÿ≥ŸäÿØÿ© {sender} ÿßŸÑŸÖÿ≠ÿ™ÿ±ŸÖ/ÿ©ÿå

ÿ¥ŸÉÿ±ÿßŸã ŸÑŸÖÿ™ÿßÿ®ÿπÿ™ŸÉŸÖ.

ÿ®ÿÆÿµŸàÿµ ŸÖŸàÿ∂ŸàÿπŸÉŸÖÿå ŸÜŸàÿØ ÿ•ŸÅÿßÿØÿ™ŸÉŸÖ ÿ®ÿ£ŸÜ [ÿ£ÿ∂ŸÅ ÿßŸÑÿ≠ÿßŸÑÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ©].

ÿ≥ŸÜÿ®ŸÇŸäŸÉŸÖ ÿπŸÑŸâ ÿßÿ∑ŸÑÿßÿπ ÿ®ÿ£Ÿä ÿ™ÿ≠ÿØŸäÿ´ÿßÿ™.

ŸÖÿπ ÿ£ÿ∑Ÿäÿ® ÿßŸÑÿ™ÿ≠Ÿäÿßÿ™ÿå
ŸÅÿ±ŸäŸÇ ÿßŸÑŸÖÿ™ÿßÿ®ÿπÿ©""",
        
        "ÿπÿ±ÿ∂": f"""ÿßŸÑÿ≥ŸäÿØ/ÿßŸÑÿ≥ŸäÿØÿ© {sender} ÿßŸÑŸÖÿ≠ÿ™ÿ±ŸÖ/ÿ©ÿå

ÿ¥ŸÉÿ±ÿßŸã ŸÑÿ™ŸàÿßÿµŸÑŸÉŸÖ Ÿàÿπÿ±ÿ∂ŸÉŸÖ ÿßŸÑŸÉÿ±ŸäŸÖ.

ÿ≥ŸÜŸÇŸàŸÖ ÿ®ÿØÿ±ÿßÿ≥ÿ© ÿßŸÑÿπÿ±ÿ∂ ÿßŸÑŸÖŸÇÿØŸÖ ŸàÿßŸÑÿ±ÿØ ÿπŸÑŸäŸÉŸÖ ŸÅŸä ÿ£ŸÇÿ±ÿ® ŸàŸÇÿ™.

ŸÖÿπ ÿ£ÿ∑Ÿäÿ® ÿßŸÑÿ™ÿ≠Ÿäÿßÿ™ÿå
ŸÅÿ±ŸäŸÇ ÿßŸÑŸÖÿ¥ÿ™ÿ±Ÿäÿßÿ™""",
        
        "ÿ£ÿÆÿ±Ÿâ": f"""ÿßŸÑÿ≥ŸäÿØ/ÿßŸÑÿ≥ŸäÿØÿ© {sender} ÿßŸÑŸÖÿ≠ÿ™ÿ±ŸÖ/ÿ©ÿå

ÿ¥ŸÉÿ±ÿßŸã ŸÑÿ™ŸàÿßÿµŸÑŸÉŸÖ ŸÖÿπŸÜÿß.

ÿ™ŸÖ ÿßÿ≥ÿ™ŸÑÿßŸÖ ÿ±ÿ≥ÿßŸÑÿ™ŸÉŸÖ Ÿàÿ≥ŸÜŸÇŸàŸÖ ÿ®ÿßŸÑÿ±ÿØ ÿπŸÑŸäŸÉŸÖ ŸÇÿ±Ÿäÿ®ÿßŸã.

ŸÖÿπ ÿ£ÿ∑Ÿäÿ® ÿßŸÑÿ™ÿ≠Ÿäÿßÿ™ÿå
ŸÅÿ±ŸäŸÇ ÿÆÿØŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ°"""
    }
    
    return templates.get(intent, templates["ÿ£ÿÆÿ±Ÿâ"])


# ============ LangGraph Nodes ============

async def ingest_node(state: AgentState) -> AgentState:
    """Step 1: Ingest and clean the message"""
    state["processing_step"] = "ÿßÿ≥ÿ™ŸÑÿßŸÖ"
    
    # Clean the message
    raw = state["raw_message"].strip()
    
    # Detect message type if not specified
    if not state.get("message_type"):
        if "@" in raw and "subject" in raw.lower():
            state["message_type"] = "email"
        elif any(x in raw for x in ["Ÿàÿßÿ™ÿ≥ÿßÿ®", "whatsapp", "üì±"]):
            state["message_type"] = "whatsapp"
        else:
            state["message_type"] = "general"
    
    return state


async def classify_node(state: AgentState) -> AgentState:
    """Step 2: Classify intent, urgency, and sentiment"""
    state["processing_step"] = "ÿ™ÿµŸÜŸäŸÅ"
    
    # Try LLM first ‚Äì structured JSON output in Arabic business context
    history_block = ""
    if state.get("conversation_history"):
        history_block = f"\nÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ© ŸÖÿπ Ÿáÿ∞ÿß ÿßŸÑÿπŸÖŸäŸÑ (ŸÖŸÜ ÿßŸÑÿ£ÿ≠ÿØÿ´ ÿ•ŸÑŸâ ÿßŸÑÿ£ŸÇÿØŸÖ):\n{state['conversation_history']}\n"

    prompt = f"""ÿ£ŸÜÿ™ ÿÆÿ®Ÿäÿ± ÿÆÿØŸÖÿ© ÿπŸÖŸÑÿßÿ° ŸäÿØÿπŸÖ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸàŸÑÿ∫ÿßÿ™ ÿ£ÿÆÿ±Ÿâ.
ÿ≠ŸÑŸÑ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿ™ÿßŸÑŸäÿ© Ÿàÿ£ÿπÿ∑ŸÜŸä:
1. ÿßŸÑŸÜŸäÿ© (intent): ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ÿå ÿ∑ŸÑÿ® ÿÆÿØŸÖÿ©ÿå ÿ¥ŸÉŸàŸâÿå ŸÖÿ™ÿßÿ®ÿπÿ©ÿå ÿπÿ±ÿ∂ÿå ÿ£ÿÆÿ±Ÿâ
2. ÿßŸÑÿ£ŸáŸÖŸäÿ© (urgency): ÿπÿßÿ¨ŸÑÿå ÿπÿßÿØŸäÿå ŸÖŸÜÿÆŸÅÿ∂
3. ÿßŸÑŸÖÿ¥ÿßÿπÿ± (sentiment): ÿ•Ÿäÿ¨ÿßÿ®Ÿäÿå ŸÖÿ≠ÿßŸäÿØÿå ÿ≥ŸÑÿ®Ÿä
4. ÿßŸÑŸÑÿ∫ÿ© (language): ar, en, fr, ÿ£Ÿà ÿ±ŸÖÿ≤ ISO ÿ•ŸÜ ÿ£ŸÖŸÉŸÜ
5. ÿßŸÑŸÑŸáÿ¨ÿ© (dialect): ÿ≥Ÿàÿ±Ÿäÿå ÿ≥ÿπŸàÿØŸäÿå ŸÖÿµÿ±Ÿäÿå ÿÆŸÑŸäÿ¨Ÿäÿå ŸÅÿµÿ≠Ÿâÿå ÿ£Ÿà Other

ÿßÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ≥ŸäÿßŸÇ ÿßŸÑÿ∑ÿ®ŸäÿπŸä ŸÑŸÑŸÖÿ≠ÿßÿØÿ´ÿ©ÿå Ÿàÿ™ÿ¨ŸÜÿ® ÿßŸÑÿ≠ŸÉŸÖ ŸÖŸÜ ŸÉŸÑŸÖÿ© Ÿàÿßÿ≠ÿØÿ© ŸÅŸÇÿ∑.
{history_block}
ÿßŸÑŸÜÿµ ÿßŸÑÿ≠ÿßŸÑŸä:
{state['raw_message']}

ÿ£ÿ±ÿ¨ÿπ ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ© ÿ®ÿµŸäÿ∫ÿ© JSON ŸÅŸÇÿ∑ ÿ®Ÿáÿ∞ÿß ÿßŸÑÿ¥ŸÉŸÑ:
{{"intent": "ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±", "urgency": "ÿπÿßÿØŸä", "sentiment": "ŸÖÿ≠ÿßŸäÿØ", "language": "ar", "dialect": "ÿ¥ÿßŸÖŸä"}}"""

    llm_response = await call_llm(
        prompt,
        system=build_system_prompt(state.get("preferences")),
        json_mode=True,
    )
    
    if llm_response:
        try:
            classification = json.loads(llm_response)
            state["intent"] = classification.get("intent", "ÿ£ÿÆÿ±Ÿâ")
            state["urgency"] = classification.get("urgency", "ÿπÿßÿØŸä")
            state["sentiment"] = classification.get("sentiment", "ŸÖÿ≠ÿßŸäÿØ")
            state["language"] = classification.get("language") or "ar"
            state["dialect"] = classification.get("dialect")
            return state
        except json.JSONDecodeError:
            pass
    
    # Fallback to rule-based
    classification = rule_based_classify(state["raw_message"])
    state["intent"] = classification["intent"]
    state["urgency"] = classification["urgency"]
    state["sentiment"] = classification["sentiment"]
    
    return state


async def extract_node(state: AgentState) -> AgentState:
    """Step 3: Extract key information"""
    state["processing_step"] = "ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨"
    
    # Extract entities using regex (reliable, no LLM needed)
    entities = extract_entities(state["raw_message"])
    state["extracted_entities"] = entities
    
    # Set sender info from entities if found
    if entities.get("mentioned_name"):
        state["sender_name"] = entities["mentioned_name"]
    if entities.get("emails"):
        state["sender_contact"] = entities["emails"][0]
    elif entities.get("phones"):
        state["sender_contact"] = entities["phones"][0]
    
    # Try LLM for key points extraction
    history_block = ""
    if state.get("conversation_history"):
        history_block = f"\nÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ© ŸÖÿπ Ÿáÿ∞ÿß ÿßŸÑÿπŸÖŸäŸÑ (ŸÖŸÜ ÿßŸÑÿ£ÿ≠ÿØÿ´ ÿ•ŸÑŸâ ÿßŸÑÿ£ŸÇÿØŸÖ):\n{state['conversation_history']}\n"

    prompt = f"""ÿ£ŸÜÿ™ ŸÖÿ≥ÿßÿπÿØ ŸäÿØÿπŸÖ ŸÅÿ±ŸäŸÇ ÿÆÿØŸÖÿ© ÿßŸÑÿπŸÖŸÑÿßÿ°.
ŸÖŸÜ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿ™ÿßŸÑŸäÿ© ÿßÿ≥ÿ™ÿÆÿ±ÿ¨ ÿ®ÿßÿÆÿ™ÿµÿßÿ±:
1. ÿßŸÑŸÜŸÇÿßÿ∑ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ© ÿßŸÑÿ™Ÿä Ÿäÿ∞ŸÉÿ±Ÿáÿß ÿßŸÑÿπŸÖŸäŸÑ (3 ŸÜŸÇÿßÿ∑ ŸÉÿ≠ÿØ ÿ£ŸÇÿµŸâ).
2. ÿ£ŸáŸÖ ÿßŸÑÿ•ÿ¨ÿ±ÿßÿ°ÿßÿ™ ÿ£Ÿà ÿßŸÑÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑÿ™Ÿä ŸäŸÜÿ®ÿ∫Ÿä ÿπŸÑŸâ ÿßŸÑŸÅÿ±ŸäŸÇ ÿßŸÑŸÇŸäÿßŸÖ ÿ®Ÿáÿß.

Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ŸÉŸàŸÜ ÿßŸÑŸÑÿ∫ÿ© ÿπÿ±ÿ®Ÿäÿ© ŸÅÿµÿ≠Ÿâ ÿ®ÿ≥Ÿäÿ∑ÿ© ŸàŸÖÿ®ÿßÿ¥ÿ±ÿ©.
{history_block}
ŸÜÿµ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ©:
{state['raw_message']}

ÿ£ÿ±ÿ¨ÿπ ÿßŸÑŸÜÿ™Ÿäÿ¨ÿ© ÿ®ÿµŸäÿ∫ÿ© JSON ŸÅŸÇÿ∑ ÿ®Ÿáÿ∞ÿß ÿßŸÑÿ¥ŸÉŸÑ:
{{"key_points": ["ŸÜŸÇÿ∑ÿ© ŸÖÿÆÿ™ÿµÿ±ÿ© 1", "ŸÜŸÇÿ∑ÿ© ŸÖÿÆÿ™ÿµÿ±ÿ© 2"], "action_items": ["ÿ•ÿ¨ÿ±ÿßÿ° Ÿàÿßÿ∂ÿ≠ 1"]}}"""

    llm_response = await call_llm(
        prompt,
        system=build_system_prompt(state.get("preferences")),
        json_mode=True,
    )
    
    if llm_response:
        try:
            extracted = json.loads(llm_response)
            state["key_points"] = extracted.get("key_points", [])
            state["action_items"] = extracted.get("action_items", [])
            return state
        except json.JSONDecodeError:
            pass
    
    # Fallback: Basic extraction
    sentences = state["raw_message"].split('.')
    state["key_points"] = [s.strip() for s in sentences[:3] if s.strip()]
    state["action_items"] = ["ŸÖÿ±ÿßÿ¨ÿπÿ© ÿßŸÑÿ∑ŸÑÿ®", "ÿßŸÑÿ±ÿØ ÿπŸÑŸâ ÿßŸÑÿπŸÖŸäŸÑ"]
    
    return state


async def draft_node(state: AgentState) -> AgentState:
    """Step 4: Draft a response"""
    state["processing_step"] = "ÿµŸäÿßÿ∫ÿ©"
    
    sender = state.get("sender_name", "ÿßŸÑÿπŸÖŸäŸÑ ÿßŸÑŸÉÿ±ŸäŸÖ")
    intent = state.get("intent", "ÿ£ÿÆÿ±Ÿâ")
    key_points = state.get("key_points", [])
    
    # Try LLM for natural, personalized Arabic response
    history_block = ""
    if state.get("conversation_history"):
        history_block = f"\nÿ≥ŸäÿßŸÇ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿ≥ÿßÿ®ŸÇÿ© ŸÖÿπ Ÿáÿ∞ÿß ÿßŸÑÿπŸÖŸäŸÑ (ŸÖŸÜ ÿßŸÑÿ£ÿ≠ÿØÿ´ ÿ•ŸÑŸâ ÿßŸÑÿ£ŸÇÿØŸÖ):\n{state['conversation_history']}\n"

    prompt = f"""ÿ£ŸÜÿ™ ŸÖŸàÿ∏ŸÅ ÿÆÿØŸÖÿ© ÿπŸÖŸÑÿßÿ° ŸÖÿ≠ÿ™ÿ±ŸÅ ŸÅŸä ÿ¥ÿ±ŸÉÿ© ÿπÿ±ÿ®Ÿäÿ©.
ÿßŸÉÿ™ÿ® ÿ±ÿØÿßŸã ÿ®ÿ¥ÿ±ŸäÿßŸã ÿ∑ÿ®ŸäÿπŸäÿßŸã ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑŸÅÿµÿ≠Ÿâ ÿßŸÑŸÖÿ®ÿ≥Ÿëÿ∑ÿ© (ŸÑŸäÿ≥ÿ™ ÿ±ÿ≥ŸÖŸäÿ© ÿ¨ÿØÿßŸã ŸàŸÑÿß ÿπÿßŸÖŸäÿ©).

ÿßŸÑŸÖÿ∑ŸÑŸàÿ® ŸÖŸÜ ÿßŸÑÿ±ÿØ:
- ÿ£ŸÜ ŸäŸÉŸàŸÜ ŸÖŸàÿ¨ŸáÿßŸã ŸÖÿ®ÿßÿ¥ÿ±ÿ© ÿ•ŸÑŸâ ÿßŸÑÿπŸÖŸäŸÑ ({sender}) ÿ•ŸÜ ÿ£ŸÖŸÉŸÜ ÿ∞ŸÉÿ± ÿßŸÑÿßÿ≥ŸÖ.
- ÿ£ŸÜ ŸäŸàÿ∂ÿ≠ ÿ£ŸÜŸÉ ŸÇÿ±ÿ£ÿ™ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ŸàŸÅŸáŸÖÿ™ ŸÖÿ∂ŸÖŸàŸÜŸáÿß (ÿ®ÿßÿÆÿ™ÿµÿßÿ±).
- ÿ£ŸÜ ŸäŸÇÿØŸÖ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿ£Ÿà ÿÆÿ∑Ÿàÿßÿ™ Ÿàÿßÿ∂ÿ≠ÿ© ŸàŸÖÿ≠ÿØÿØÿ©.
- ÿ£ŸÜ ŸäŸÉŸàŸÜ ŸÖÿ¥ÿ¨ÿπÿßŸã ŸàŸÑÿ∑ŸäŸÅÿßŸãÿå ÿ®ÿØŸàŸÜ ŸÖÿ®ÿßŸÑÿ∫ÿ© ŸÅŸä ÿßŸÑŸÖÿ¨ÿßŸÖŸÑÿßÿ™ ÿ£Ÿà ÿßŸÑÿ¨ŸÖŸÑ ÿßŸÑŸÖÿ™ŸÉÿ±ÿ±ÿ©.
- ÿßŸÑÿ∑ŸàŸÑ ÿßŸÑŸÖÿ™ŸàŸÇÿπ: ŸÖŸÜ 3 ÿ•ŸÑŸâ 6 ÿ£ÿ≥ÿ∑ÿ± ŸÉÿ≠ÿØ ÿ£ŸÇÿµŸâ.

ŸÜŸàÿπ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© (ŸÜŸäÿ© ÿßŸÑÿπŸÖŸäŸÑ): {intent}
ÿßŸÑŸÜŸÇÿßÿ∑ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿäÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿ±ÿ¨ÿ©: {', '.join(key_points) or 'ŸÑŸÖ Ÿäÿ™ŸÖ ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ŸÜŸÇÿßÿ∑ Ÿàÿßÿ∂ÿ≠ÿ©'}
{history_block}
ŸÜÿµ ÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿπŸÖŸäŸÑ ÿßŸÑÿ≠ÿßŸÑŸäÿ©:
{state['raw_message']}

ÿßŸÉÿ™ÿ® ÿßŸÑÿ±ÿØ ŸÅŸÇÿ∑ ÿ®ÿØŸàŸÜ ÿ£Ÿä ÿ¥ÿ±ÿ≠ ÿ•ÿ∂ÿßŸÅŸä ÿ£Ÿà ÿ™ÿπÿØÿßÿØ ŸÜŸÇÿ∑Ÿä."""

    llm_response = await call_llm(
        prompt,
        system=build_system_prompt(state.get("preferences")),
        json_mode=False,
        max_tokens=400,
    )
    
    if llm_response and len(llm_response.strip()) > 40:
        state["draft_response"] = llm_response.strip()
    else:
        # Use template-based response
        state["draft_response"] = generate_rule_based_response(state)
    
    # Generate summary
    state["summary"] = f"ÿ±ÿ≥ÿßŸÑÿ© {intent} ŸÖŸÜ {sender}. ÿßŸÑŸÖÿ¥ÿßÿπÿ±: {state.get('sentiment', 'ŸÖÿ≠ÿßŸäÿØ')}. ÿßŸÑÿ£ŸáŸÖŸäÿ©: {state.get('urgency', 'ÿπÿßÿØŸä')}."
    
    # Suggested actions based on intent
    actions_map = {
        "ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±": ["ÿßŸÑÿ±ÿØ ÿπŸÑŸâ ÿßŸÑÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±", "ÿ•ÿ∂ÿßŸÅÿ© ŸÑŸÑÿ£ÿ≥ÿ¶ŸÑÿ© ÿßŸÑÿ¥ÿßÿ¶ÿπÿ©"],
        "ÿ∑ŸÑÿ® ÿÆÿØŸÖÿ©": ["ÿ•ŸÜÿ¥ÿßÿ° ÿ∑ŸÑÿ® ÿ¨ÿØŸäÿØ", "ÿ™ÿ≠ÿØŸäÿØ ŸÖŸàÿπÿØ", "ÿ•ÿ±ÿ≥ÿßŸÑ ÿπÿ±ÿ∂ ÿ≥ÿπÿ±"],
        "ÿ¥ŸÉŸàŸâ": ["ÿ™ÿµÿπŸäÿØ ŸÑŸÑŸÖÿØŸäÿ±", "ŸÅÿ™ÿ≠ ÿ™ÿ∞ŸÉÿ±ÿ© ÿØÿπŸÖ", "ÿßŸÑÿßÿ™ÿµÿßŸÑ ÿ®ÿßŸÑÿπŸÖŸäŸÑ"],
        "ŸÖÿ™ÿßÿ®ÿπÿ©": ["ÿ™ÿ≠ÿØŸäÿ´ ÿ≠ÿßŸÑÿ© ÿßŸÑÿ∑ŸÑÿ®", "ÿ•ÿ±ÿ≥ÿßŸÑ ÿ™ŸÇÿ±Ÿäÿ±"],
        "ÿπÿ±ÿ∂": ["ÿØÿ±ÿßÿ≥ÿ© ÿßŸÑÿπÿ±ÿ∂", "ÿ™ÿ≠ŸàŸäŸÑ ŸÑŸÑŸÖÿ¥ÿ™ÿ±Ÿäÿßÿ™"],
        "ÿ£ÿÆÿ±Ÿâ": ["ŸÖÿ±ÿßÿ¨ÿπÿ© ŸäÿØŸàŸäÿ©", "ÿ™ÿµŸÜŸäŸÅ ÿßŸÑÿ±ÿ≥ÿßŸÑÿ©"]
    }
    state["suggested_actions"] = actions_map.get(intent, actions_map["ÿ£ÿÆÿ±Ÿâ"])
    
    return state


# ============ Build the Graph ============

def create_inbox_agent():
    """Create the InboxCRM LangGraph agent"""
    
    # Create the graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("ingest", ingest_node)
    workflow.add_node("classify", classify_node)
    workflow.add_node("extract", extract_node)
    workflow.add_node("draft", draft_node)
    
    # Define edges (linear pipeline)
    workflow.set_entry_point("ingest")
    workflow.add_edge("ingest", "classify")
    workflow.add_edge("classify", "extract")
    workflow.add_edge("extract", "draft")
    workflow.add_edge("draft", END)
    
    # Compile
    return workflow.compile()


# Singleton agent instance
_agent = None

def get_agent():
    """Get or create the agent instance"""
    global _agent
    if _agent is None:
        _agent = create_inbox_agent()
    return _agent


async def process_message(
    message: str,
    message_type: str = None,
    sender_name: str = None,
    sender_contact: str = None,
    preferences: Optional[Dict[str, Any]] = None,
    conversation_history: Optional[str] = None,
) -> dict:
    """Process a message through the InboxCRM pipeline"""
    
    agent = get_agent()
    
    # Initial state
    initial_state: AgentState = {
        "raw_message": message,
        "message_type": message_type or "general",
        "intent": "",
        "urgency": "",
        "sentiment": "",
        "sender_name": sender_name,
        "sender_contact": sender_contact,
        "key_points": [],
        "action_items": [],
        "extracted_entities": {},
        "summary": "",
        "draft_response": "",
        "suggested_actions": [],
        "error": None,
        "processing_step": "",
        "preferences": preferences,
        "conversation_history": conversation_history,
    }
    
    try:
        # Run the agent
        final_state = await agent.ainvoke(initial_state)
        return {
            "success": True,
            "data": {
                "intent": final_state["intent"],
                "urgency": final_state["urgency"],
                "sentiment": final_state["sentiment"],
                "language": final_state.get("language"),
                "dialect": final_state.get("dialect"),
                "sender_name": final_state["sender_name"],
                "sender_contact": final_state["sender_contact"],
                "key_points": final_state["key_points"],
                "action_items": final_state["action_items"],
                "extracted_entities": final_state["extracted_entities"],
                "summary": final_state["summary"],
                "draft_response": final_state["draft_response"],
                "suggested_actions": final_state["suggested_actions"],
                "message_type": final_state["message_type"]
            }
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ŸÅŸä ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©: {str(e)}"
        }

