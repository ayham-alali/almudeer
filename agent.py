"""
Al-Mudeer - LangGraph InboxCRM Agent
Implements: Ingest -> Classify -> Extract -> Draft pipeline
Optimized for low bandwidth with text-only responses
"""

import json
import re
from typing import TypedDict, Literal, Optional
from dataclasses import dataclass
import httpx
import os

# LangGraph imports
from langgraph.graph import StateGraph, END

# Configuration
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3.2")  # or any Arabic-capable model

# System prompt for Arabic business context
SYSTEM_PROMPT = """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…ÙƒØªØ¨ÙŠ Ø°ÙƒÙŠ Ù„Ø´Ø±ÙƒØ© Ø³ÙˆØ±ÙŠØ©. ØªØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ù‡Ù†ÙŠ ÙˆÙ…Ù‡Ø°Ø¨.
ØªÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø³ÙˆØ±ÙŠ ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠ Ø¬ÙŠØ¯Ø§Ù‹.
Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ÙˆØ§Ø±Ø¯Ø© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØµÙŠØ§ØºØ© Ø±Ø¯ÙˆØ¯ Ù…Ù†Ø§Ø³Ø¨Ø©.
ÙƒÙ† Ù…ÙˆØ¬Ø²Ø§Ù‹ ÙˆÙ…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙÙŠ Ø±Ø¯ÙˆØ¯Ùƒ Ù„ØªÙˆÙÙŠØ± Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""


class AgentState(TypedDict):
    """State for the InboxCRM agent"""
    # Input
    raw_message: str
    message_type: str  # email, whatsapp, general
    
    # Classification
    intent: str  # Ø§Ø³ØªÙØ³Ø§Ø±, Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©, Ø´ÙƒÙˆÙ‰, Ù…ØªØ§Ø¨Ø¹Ø©, Ø¹Ø±Ø¶, Ø£Ø®Ø±Ù‰
    urgency: str  # Ø¹Ø§Ø¬Ù„, Ø¹Ø§Ø¯ÙŠ, Ù…Ù†Ø®ÙØ¶
    sentiment: str  # Ø¥ÙŠØ¬Ø§Ø¨ÙŠ, Ù…Ø­Ø§ÙŠØ¯, Ø³Ù„Ø¨ÙŠ
    
    # Extraction
    sender_name: Optional[str]
    sender_contact: Optional[str]
    key_points: list[str]
    action_items: list[str]
    extracted_entities: dict  # dates, amounts, product names, etc.
    
    # Output
    summary: str
    draft_response: str
    suggested_actions: list[str]
    
    # Metadata
    error: Optional[str]
    processing_step: str


async def call_llm(prompt: str, system: str = SYSTEM_PROMPT) -> str:
    """Call Ollama or fallback to rule-based processing"""
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{OLLAMA_BASE_URL}/api/generate",
                json={
                    "model": OLLAMA_MODEL,
                    "prompt": prompt,
                    "system": system,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 500  # Limit response length for bandwidth
                    }
                }
            )
            if response.status_code == 200:
                return response.json().get("response", "")
    except Exception as e:
        print(f"LLM call failed: {e}")
    
    # Fallback to rule-based if Ollama is not available
    return None


def rule_based_classify(message: str) -> dict:
    """Rule-based classification fallback (works offline)"""
    message_lower = message.lower()
    
    # Intent detection
    intent = "Ø£Ø®Ø±Ù‰"
    if any(word in message for word in ["Ø³Ø¹Ø±", "ÙƒÙ…", "ØªÙƒÙ„ÙØ©", "Ø£Ø³Ø¹Ø§Ø±"]):
        intent = "Ø§Ø³ØªÙØ³Ø§Ø±"
    elif any(word in message for word in ["Ø£Ø±ÙŠØ¯", "Ø£Ø±ØºØ¨", "Ø·Ù„Ø¨", "Ø§Ø­ØªØ§Ø¬", "Ù†Ø±ÙŠØ¯"]):
        intent = "Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©"
    elif any(word in message for word in ["Ø´ÙƒÙˆÙ‰", "Ù…Ø´ÙƒÙ„Ø©", "Ù„Ù… ÙŠØ¹Ù…Ù„", "ØªØ£Ø®Ø±", "Ø³ÙŠØ¡"]):
        intent = "Ø´ÙƒÙˆÙ‰"
    elif any(word in message for word in ["Ù…ØªØ§Ø¨Ø¹Ø©", "Ø¨Ø®ØµÙˆØµ", "Ø§Ø³ØªÙƒÙ…Ø§Ù„", "ØªØ°ÙƒÙŠØ±"]):
        intent = "Ù…ØªØ§Ø¨Ø¹Ø©"
    elif any(word in message for word in ["Ø¹Ø±Ø¶", "Ø®ØµÙ…", "ØªØ®ÙÙŠØ¶", "ÙØ±ØµØ©"]):
        intent = "Ø¹Ø±Ø¶"
    
    # Urgency detection
    urgency = "Ø¹Ø§Ø¯ÙŠ"
    if any(word in message for word in ["Ø¹Ø§Ø¬Ù„", "ÙÙˆØ±ÙŠ", "Ø§Ù„ÙŠÙˆÙ…", "Ø§Ù„Ø¢Ù†", "Ø¶Ø±ÙˆØ±ÙŠ"]):
        urgency = "Ø¹Ø§Ø¬Ù„"
    elif any(word in message for word in ["Ù„Ø§Ø­Ù‚Ø§Ù‹", "Ø¹Ù†Ø¯Ù…Ø§", "Ù…ØªÙ‰ Ù…Ø§"]):
        urgency = "Ù…Ù†Ø®ÙØ¶"
    
    # Sentiment detection
    sentiment = "Ù…Ø­Ø§ÙŠØ¯"
    if any(word in message for word in ["Ø´ÙƒØ±Ø§Ù‹", "Ù…Ù…ØªØ§Ø²", "Ø±Ø§Ø¦Ø¹", "Ø³Ø¹ÙŠØ¯", "Ù…Ø³Ø±ÙˆØ±"]):
        sentiment = "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ"
    elif any(word in message for word in ["ØºØ§Ø¶Ø¨", "Ù…Ø­Ø¨Ø·", "Ø³ÙŠØ¡", "Ù…Ø³ØªØ§Ø¡", "Ù„Ù„Ø£Ø³Ù"]):
        sentiment = "Ø³Ù„Ø¨ÙŠ"
    
    return {"intent": intent, "urgency": urgency, "sentiment": sentiment}


def extract_entities(message: str) -> dict:
    """Extract entities using regex patterns"""
    entities = {}
    
    # Phone numbers (Syrian/Arabic format)
    phone_patterns = [
        r'(?:00963|\+963|0)?9\d{8}',  # Syrian mobile
        r'(?:00963|\+963|0)?11\d{7}',  # Damascus landline
        r'\d{3}[-.\s]?\d{3}[-.\s]?\d{4}',  # General format
    ]
    phones = []
    for pattern in phone_patterns:
        phones.extend(re.findall(pattern, message))
    if phones:
        entities["phones"] = list(set(phones))
    
    # Email
    emails = re.findall(r'[\w\.-]+@[\w\.-]+\.\w+', message)
    if emails:
        entities["emails"] = emails
    
    # Dates (Arabic format)
    dates = re.findall(r'\d{1,2}[/\-]\d{1,2}[/\-]\d{2,4}', message)
    if dates:
        entities["dates"] = dates
    
    # Money amounts
    amounts = re.findall(r'(\d+(?:,\d{3})*(?:\.\d+)?)\s*(?:Ù„\.Ø³|Ù„ÙŠØ±Ø©|Ø¯ÙˆÙ„Ø§Ø±|\$|USD)', message)
    if amounts:
        entities["amounts"] = amounts
    
    # Extract possible name (after Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø©/Ø§Ù„Ø£Ø³ØªØ§Ø°)
    name_match = re.search(r'(?:Ø§Ù„Ø³ÙŠØ¯|Ø§Ù„Ø³ÙŠØ¯Ø©|Ø§Ù„Ø£Ø³ØªØ§Ø°|Ø§Ù„Ø£Ø³ØªØ§Ø°Ø©|Ø£Ø®ÙŠ|Ø£Ø®ØªÙŠ)\s+([\u0600-\u06FF\s]+)', message)
    if name_match:
        entities["mentioned_name"] = name_match.group(1).strip()
    
    return entities


def generate_rule_based_response(state: dict) -> str:
    """Generate a draft response based on intent"""
    intent = state.get("intent", "Ø£Ø®Ø±Ù‰")
    sender = state.get("sender_name", "Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„ÙƒØ±ÙŠÙ…")
    
    templates = {
        "Ø§Ø³ØªÙØ³Ø§Ø±": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„ÙƒÙ… Ù…Ø¹Ù†Ø§.

Ø¨Ø®ØµÙˆØµ Ø§Ø³ØªÙØ³Ø§Ø±ÙƒÙ…ØŒ Ù†ÙˆØ¯ Ø¥ÙØ§Ø¯ØªÙƒÙ… Ø¨Ø£Ù† [Ø£Ø¶Ù Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù‡Ù†Ø§].

Ù†Ø±Ø­Ø¨ Ø¨Ø£ÙŠ Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©.

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡""",
        
        "Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„Ø«Ù‚ØªÙƒÙ… Ø¨Ø®Ø¯Ù…Ø§ØªÙ†Ø§.

ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨ÙƒÙ… Ø¨Ù†Ø¬Ø§Ø­ ÙˆØ³ÙŠØªÙ… Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙƒÙ… Ù‚Ø±ÙŠØ¨Ø§Ù‹ Ù„Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª.

Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø£Ùˆ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±ØŒ Ù†Ø­Ù† Ø¨Ø®Ø¯Ù…ØªÙƒÙ….

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª""",
        
        "Ø´ÙƒÙˆÙ‰": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ù†Ø¹ØªØ°Ø± Ø¹Ù† Ø£ÙŠ Ø¥Ø²Ø¹Ø§Ø¬ Ø³Ø¨Ø¨Ù†Ø§Ù‡ Ù„ÙƒÙ….

ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒÙ… ÙˆØ³ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø£Ù‚ØµÙ‰ Ø³Ø±Ø¹Ø©.
Ø³Ù†ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙƒÙ… Ø®Ù„Ø§Ù„ [Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø¯Ø©] Ù„Ø¥Ø·Ù„Ø§Ø¹ÙƒÙ… Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ¬Ø¯Ø§Øª.

Ù†Ù‚Ø¯Ø± ØµØ¨Ø±ÙƒÙ… ÙˆØªÙÙ‡Ù…ÙƒÙ….

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡""",
        
        "Ù…ØªØ§Ø¨Ø¹Ø©": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„Ù…ØªØ§Ø¨Ø¹ØªÙƒÙ….

Ø¨Ø®ØµÙˆØµ Ù…ÙˆØ¶ÙˆØ¹ÙƒÙ…ØŒ Ù†ÙˆØ¯ Ø¥ÙØ§Ø¯ØªÙƒÙ… Ø¨Ø£Ù† [Ø£Ø¶Ù Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©].

Ø³Ù†Ø¨Ù‚ÙŠÙƒÙ… Ø¹Ù„Ù‰ Ø§Ø·Ù„Ø§Ø¹ Ø¨Ø£ÙŠ ØªØ­Ø¯ÙŠØ«Ø§Øª.

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©""",
        
        "Ø¹Ø±Ø¶": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„ÙƒÙ… ÙˆØ¹Ø±Ø¶ÙƒÙ… Ø§Ù„ÙƒØ±ÙŠÙ….

Ø³Ù†Ù‚ÙˆÙ… Ø¨Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø¯Ù… ÙˆØ§Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙƒÙ… ÙÙŠ Ø£Ù‚Ø±Ø¨ ÙˆÙ‚Øª.

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª""",
        
        "Ø£Ø®Ø±Ù‰": f"""Ø§Ù„Ø³ÙŠØ¯/Ø§Ù„Ø³ÙŠØ¯Ø© {sender} Ø§Ù„Ù…Ø­ØªØ±Ù…/Ø©ØŒ

Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙˆØ§ØµÙ„ÙƒÙ… Ù…Ø¹Ù†Ø§.

ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø³Ø§Ù„ØªÙƒÙ… ÙˆØ³Ù†Ù‚ÙˆÙ… Ø¨Ø§Ù„Ø±Ø¯ Ø¹Ù„ÙŠÙƒÙ… Ù‚Ø±ÙŠØ¨Ø§Ù‹.

Ù…Ø¹ Ø£Ø·ÙŠØ¨ Ø§Ù„ØªØ­ÙŠØ§ØªØŒ
ÙØ±ÙŠÙ‚ Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡"""
    }
    
    return templates.get(intent, templates["Ø£Ø®Ø±Ù‰"])


# ============ LangGraph Nodes ============

async def ingest_node(state: AgentState) -> AgentState:
    """Step 1: Ingest and clean the message"""
    state["processing_step"] = "Ø§Ø³ØªÙ„Ø§Ù…"
    
    # Clean the message
    raw = state["raw_message"].strip()
    
    # Detect message type if not specified
    if not state.get("message_type"):
        if "@" in raw and "subject" in raw.lower():
            state["message_type"] = "email"
        elif any(x in raw for x in ["ÙˆØ§ØªØ³Ø§Ø¨", "whatsapp", "ğŸ“±"]):
            state["message_type"] = "whatsapp"
        else:
            state["message_type"] = "general"
    
    return state


async def classify_node(state: AgentState) -> AgentState:
    """Step 2: Classify intent, urgency, and sentiment"""
    state["processing_step"] = "ØªØµÙ†ÙŠÙ"
    
    # Try LLM first
    prompt = f"""Ø­Ù„Ù„ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙˆØ£Ø¹Ø·Ù†ÙŠ:
1. Ø§Ù„Ù†ÙŠØ© (intent): Ø§Ø³ØªÙØ³Ø§Ø±ØŒ Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©ØŒ Ø´ÙƒÙˆÙ‰ØŒ Ù…ØªØ§Ø¨Ø¹Ø©ØŒ Ø¹Ø±Ø¶ØŒ Ø£Ø®Ø±Ù‰
2. Ø§Ù„Ø£Ù‡Ù…ÙŠØ© (urgency): Ø¹Ø§Ø¬Ù„ØŒ Ø¹Ø§Ø¯ÙŠØŒ Ù…Ù†Ø®ÙØ¶
3. Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (sentiment): Ø¥ÙŠØ¬Ø§Ø¨ÙŠØŒ Ù…Ø­Ø§ÙŠØ¯ØŒ Ø³Ù„Ø¨ÙŠ

Ø§Ù„Ø±Ø³Ø§Ù„Ø©:
{state['raw_message']}

Ø§Ù„Ø±Ø¯ Ø¨ØµÙŠØºØ© JSON ÙÙ‚Ø·:
{{"intent": "", "urgency": "", "sentiment": ""}}"""

    llm_response = await call_llm(prompt)
    
    if llm_response:
        try:
            # Extract JSON from response
            json_match = re.search(r'\{[^}]+\}', llm_response)
            if json_match:
                classification = json.loads(json_match.group())
                state["intent"] = classification.get("intent", "Ø£Ø®Ø±Ù‰")
                state["urgency"] = classification.get("urgency", "Ø¹Ø§Ø¯ÙŠ")
                state["sentiment"] = classification.get("sentiment", "Ù…Ø­Ø§ÙŠØ¯")
                return state
        except json.JSONDecodeError:
            pass
    
    # Fallback to rule-based
    classification = rule_based_classify(state["raw_message"])
    state["intent"] = classification["intent"]
    state["urgency"] = classification["urgency"]
    state["sentiment"] = classification["sentiment"]
    
    return state


async def extract_node(state: AgentState) -> AgentState:
    """Step 3: Extract key information"""
    state["processing_step"] = "Ø§Ø³ØªØ®Ø±Ø§Ø¬"
    
    # Extract entities using regex (reliable, no LLM needed)
    entities = extract_entities(state["raw_message"])
    state["extracted_entities"] = entities
    
    # Set sender info from entities if found
    if entities.get("mentioned_name"):
        state["sender_name"] = entities["mentioned_name"]
    if entities.get("emails"):
        state["sender_contact"] = entities["emails"][0]
    elif entities.get("phones"):
        state["sender_contact"] = entities["phones"][0]
    
    # Try LLM for key points extraction
    prompt = f"""Ù…Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©ØŒ Ø§Ø³ØªØ®Ø±Ø¬:
1. Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (3 Ù†Ù‚Ø§Ø· ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰)
2. Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©

Ø§Ù„Ø±Ø³Ø§Ù„Ø©:
{state['raw_message']}

Ø§Ù„Ø±Ø¯ Ø¨ØµÙŠØºØ© JSON:
{{"key_points": ["Ù†Ù‚Ø·Ø© 1", "Ù†Ù‚Ø·Ø© 2"], "action_items": ["Ø¥Ø¬Ø±Ø§Ø¡ 1"]}}"""

    llm_response = await call_llm(prompt)
    
    if llm_response:
        try:
            json_match = re.search(r'\{[^}]+\}', llm_response, re.DOTALL)
            if json_match:
                extracted = json.loads(json_match.group())
                state["key_points"] = extracted.get("key_points", [])
                state["action_items"] = extracted.get("action_items", [])
                return state
        except json.JSONDecodeError:
            pass
    
    # Fallback: Basic extraction
    sentences = state["raw_message"].split('.')
    state["key_points"] = [s.strip() for s in sentences[:3] if s.strip()]
    state["action_items"] = ["Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø·Ù„Ø¨", "Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…ÙŠÙ„"]
    
    return state


async def draft_node(state: AgentState) -> AgentState:
    """Step 4: Draft a response"""
    state["processing_step"] = "ØµÙŠØ§ØºØ©"
    
    sender = state.get("sender_name", "Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„ÙƒØ±ÙŠÙ…")
    intent = state.get("intent", "Ø£Ø®Ø±Ù‰")
    key_points = state.get("key_points", [])
    
    # Try LLM for natural response
    prompt = f"""Ø§ÙƒØªØ¨ Ø±Ø¯Ø§Ù‹ Ù…Ù‡Ù†ÙŠØ§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©.
Ø§Ù„Ù…Ø±Ø³Ù„: {sender}
Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {intent}
Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {', '.join(key_points)}

Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©:
{state['raw_message']}

Ø§ÙƒØªØ¨ Ø±Ø¯Ø§Ù‹ Ù…Ù‡Ø°Ø¨Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹ (Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² 100 ÙƒÙ„Ù…Ø©):"""

    llm_response = await call_llm(prompt)
    
    if llm_response and len(llm_response) > 50:
        state["draft_response"] = llm_response.strip()
    else:
        # Use template-based response
        state["draft_response"] = generate_rule_based_response(state)
    
    # Generate summary
    state["summary"] = f"Ø±Ø³Ø§Ù„Ø© {intent} Ù…Ù† {sender}. Ø§Ù„Ù…Ø´Ø§Ø¹Ø±: {state.get('sentiment', 'Ù…Ø­Ø§ÙŠØ¯')}. Ø§Ù„Ø£Ù‡Ù…ÙŠØ©: {state.get('urgency', 'Ø¹Ø§Ø¯ÙŠ')}."
    
    # Suggested actions based on intent
    actions_map = {
        "Ø§Ø³ØªÙØ³Ø§Ø±": ["Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±", "Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"],
        "Ø·Ù„Ø¨ Ø®Ø¯Ù…Ø©": ["Ø¥Ù†Ø´Ø§Ø¡ Ø·Ù„Ø¨ Ø¬Ø¯ÙŠØ¯", "ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¹Ø¯", "Ø¥Ø±Ø³Ø§Ù„ Ø¹Ø±Ø¶ Ø³Ø¹Ø±"],
        "Ø´ÙƒÙˆÙ‰": ["ØªØµØ¹ÙŠØ¯ Ù„Ù„Ù…Ø¯ÙŠØ±", "ÙØªØ­ ØªØ°ÙƒØ±Ø© Ø¯Ø¹Ù…", "Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¹Ù…ÙŠÙ„"],
        "Ù…ØªØ§Ø¨Ø¹Ø©": ["ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨", "Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ±"],
        "Ø¹Ø±Ø¶": ["Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø¹Ø±Ø¶", "ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù…Ø´ØªØ±ÙŠØ§Øª"],
        "Ø£Ø®Ø±Ù‰": ["Ù…Ø±Ø§Ø¬Ø¹Ø© ÙŠØ¯ÙˆÙŠØ©", "ØªØµÙ†ÙŠÙ Ø§Ù„Ø±Ø³Ø§Ù„Ø©"]
    }
    state["suggested_actions"] = actions_map.get(intent, actions_map["Ø£Ø®Ø±Ù‰"])
    
    return state


# ============ Build the Graph ============

def create_inbox_agent():
    """Create the InboxCRM LangGraph agent"""
    
    # Create the graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("ingest", ingest_node)
    workflow.add_node("classify", classify_node)
    workflow.add_node("extract", extract_node)
    workflow.add_node("draft", draft_node)
    
    # Define edges (linear pipeline)
    workflow.set_entry_point("ingest")
    workflow.add_edge("ingest", "classify")
    workflow.add_edge("classify", "extract")
    workflow.add_edge("extract", "draft")
    workflow.add_edge("draft", END)
    
    # Compile
    return workflow.compile()


# Singleton agent instance
_agent = None

def get_agent():
    """Get or create the agent instance"""
    global _agent
    if _agent is None:
        _agent = create_inbox_agent()
    return _agent


async def process_message(
    message: str,
    message_type: str = None,
    sender_name: str = None,
    sender_contact: str = None
) -> dict:
    """Process a message through the InboxCRM pipeline"""
    
    agent = get_agent()
    
    # Initial state
    initial_state: AgentState = {
        "raw_message": message,
        "message_type": message_type or "general",
        "intent": "",
        "urgency": "",
        "sentiment": "",
        "sender_name": sender_name,
        "sender_contact": sender_contact,
        "key_points": [],
        "action_items": [],
        "extracted_entities": {},
        "summary": "",
        "draft_response": "",
        "suggested_actions": [],
        "error": None,
        "processing_step": ""
    }
    
    try:
        # Run the agent
        final_state = await agent.ainvoke(initial_state)
        return {
            "success": True,
            "data": {
                "intent": final_state["intent"],
                "urgency": final_state["urgency"],
                "sentiment": final_state["sentiment"],
                "sender_name": final_state["sender_name"],
                "sender_contact": final_state["sender_contact"],
                "key_points": final_state["key_points"],
                "action_items": final_state["action_items"],
                "extracted_entities": final_state["extracted_entities"],
                "summary": final_state["summary"],
                "draft_response": final_state["draft_response"],
                "suggested_actions": final_state["suggested_actions"],
                "message_type": final_state["message_type"]
            }
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"
        }

